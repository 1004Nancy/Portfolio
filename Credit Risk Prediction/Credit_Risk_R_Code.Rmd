---
```{r}
library(tidyverse)
library(tidymodels)
library(solitude) # -- new package 
library(ggpubr)
library(dplyr)
library(janitor)
library(skimr)
library(kableExtra)
library(GGally)
library(kableExtra) # -- make nice looking resutls when we knitt 
library(vip)        # --  tidymodels variable importance
library(fastshap)   # -- shapley values for variable importance 
library(MASS)
library(rpart.plot) # -- plotting decision trees 
library(ranger) 
library(doParallel) 
library(tree)
library(DALEXtra)
```

```{r}
loan <- read_csv("loan_train.csv") %>%
  clean_names()

head(loan)
```

```{r}
n_cols <- names(loan %>% select_if(is.numeric) %>% dplyr::select(-id, member_id))

my_hist <- function(col){
  loan %>%
    summarise(n=n(), 
              n_miss = sum(is.na(!!as.name(col))),
              n_dist = n_distinct(!!as.name(col)),
              mean = round(mean(!!as.name(col), na.rm=TRUE),2),
              min  = min(!!as.name(col), na.rm=TRUE),
              max  = max(!!as.name(col), na.rm=TRUE)
              ) -> col_summary
  
   p1  <- ggtexttable(col_summary, rows = NULL, 
                        theme = ttheme("mOrange"))
  
loan1 <- loan %>%
  ggplot(aes(x=!!as.name(col))) +
  geom_histogram(bins=30) 

plt <- ggarrange( loan1, p1, 
          ncol = 1, nrow = 2,
          heights = c(1, 0.3)) 

print(plt)

}

for (c in n_cols){
  my_hist(c)
}
```

```{r}

loan_numeric <- loan %>% select_if(is.numeric)

loan_recipe <- recipe(~.,loan_numeric) %>%
  step_rm(id, member_id) %>%
  step_unknown(all_nominal_predictors()) %>%
  step_impute_mean(all_predictors()) %>%
  step_novel(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors())

bake_loan <- bake(loan_recipe %>% prep(), loan_numeric)

iso_forest <- isolationForest$new(
  sample_size = 2048,
  num_trees = 100,
  max_depth = 12)


iso_forest$fit(bake_loan)
train_pred <- iso_forest$predict(bake_loan)

train_pred %>%
  ggplot(aes(anomaly_score)) +
  geom_histogram(bins=20) + 
  geom_vline(xintercept = 0.65, linetype="dotted", 
                color = "blue", size=1.5) + 
  labs(title="Isolation Forest Anomaly Score Above 0.65")


# global anomaly rules
train_pred <- bind_cols(iso_forest$predict(bake_loan),bake_loan) %>%
  mutate(anomaly = as.factor(if_else(anomaly_score >= 0.65, "Anomaly","Normal")))

train_pred %>%
  arrange(anomaly_score) %>%
  count(anomaly)

fmla <- as.formula(paste("anomaly ~ ", paste(bake_loan %>% colnames(), collapse= "+")))

outlier_tree <- decision_tree(min_n=2, tree_depth=3, cost_complexity = .01) %>%
  set_mode("classification") %>%
  set_engine("rpart") %>%
  fit(fmla, data=train_pred)

outlier_tree$fit

library(rpart.plot) # -- plotting decision trees 

rpart.plot(outlier_tree$fit,clip.right.labs = FALSE, branch = .3, under = TRUE, roundint=FALSE, extra=3)

Global_anomaly_rules <- rpart.rules(outlier_tree$fit, extra = 4, cover = TRUE, clip.facs = TRUE) %>% clean_names() %>%
  filter(anomaly=="Anomaly") %>%
  mutate(rule = "IF") 


rule_cols <- Global_anomaly_rules %>% dplyr::select(starts_with("x_")) %>% colnames()

for (col in rule_cols){
Global_anomaly_rules <- Global_anomaly_rules %>%
    mutate(rule = paste(rule, !!as.name(col)))
}

as.data.frame(Global_anomaly_rules) %>%
  dplyr::select(rule, cover)






# local rule to explain your 5 most anomalous records
local_explainer <- function(ID){
  
  fmla <- as.formula(paste("anomaly ~ ", paste(bake_loan %>% colnames(), collapse= "+")))
  
  train_pred  %>%
    mutate(anomaly= as.factor(if_else(id==ID, "Anomaly", "Normal"))) -> local_df
  
  local_tree <-  decision_tree(mode="classification",
                              tree_depth = 3,
                              min_n = 1,
                              cost_complexity=0) %>%
                set_engine("rpart") %>%
                    fit(fmla,local_df)
  
  local_tree$fit
  
  #rpart.rules(local_tree$fit, extra = 4, cover = TRUE, clip.facs = TRUE)
  rpart.plot(local_tree$fit, roundint=FALSE, extra=3) %>% print()
  
  anomaly_rules <- rpart.rules(local_tree$fit, extra = 4, cover = TRUE, clip.facs = TRUE) %>% clean_names() %>%
    filter(anomaly=="Anomaly") %>%
    mutate(rule = "IF") 
  
  
  rule_cols <- anomaly_rules %>% dplyr::select(starts_with("x_")) %>% colnames()
  
  for (col in rule_cols){
  anomaly_rules <- anomaly_rules %>%
      mutate(rule = paste(rule, !!as.name(col)))
  }
  
  as.data.frame(anomaly_rules) %>%
    dplyr::select(rule, cover) %>%
    print()
}

train_pred %>%
  slice_max(order_by=anomaly_score,n=5) %>%
  pull(id) -> anomaly_vect

for (anomaly_id in anomaly_vect){
  print(anomaly_id)
  local_explainer(anomaly_id)
}


```


```{r}
loan %>% 
  skim() 
  
#set seed for repeatability
set.seed(2)
# Save the split information for an 70/30 split of the data
bsplit <- initial_split(loan, prop = 0.70)
train <- training(bsplit) 
test  <-  testing(bsplit)

# Kfold cross validation
kfold_splits <- vfold_cv(train, v=5)
```
```{r}
loan_summary <- loan %>% 
  count(loan_status) %>%
  mutate(pct = n/sum(n))
loan_summary

loan_summary %>%
  ggplot(aes(x=factor(loan_status),y=pct)) +
  geom_col()  + 
  geom_text(aes(label = round(pct*100,1)) , vjust = 2.5, colour = "white") + 
  labs(title=" loan_status is default or not", x="loan_status", y="PCT")

```
```{r}
#insert correlation matrix
cor_matrix <- loan %>%
  mutate(loan_status=as.numeric(loan_status))%>%
  select_if(is.numeric) %>%
  na.omit() %>%
  cor()
cor_matrix

library(reshape2)
cor_matrix %>% melt() %>%
  mutate(value = round(value,3)) %>%
  ggplot(aes(x=Var1, y=Var2, fill=value)) +
  geom_tile() +
   scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                        midpoint = 0, limit = c(-1,1), space = "Lab", 
                        name="Correlation") +
   theme_minimal()+ 
   theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                    size = 10, hjust = 1))+
   coord_fixed() +
   geom_text(aes(Var2, Var1, label = value), color = "black", size = 2)
```
```{r}
loan %>%
  group_by(pymnt_plan, loan_status) %>%
  summarise(n=n())

loan %>%
  ggplot(aes(pymnt_plan, fill=loan_status)) +
  geom_bar(position = "fill") +
  labs(title="relationship of loan status to pymnt_plan", x="pymnt_plan",y="pct default")


loan %>%
  group_by(grade, loan_status) %>%
  summarise(n=n())

loan %>%
  ggplot(aes(grade, fill=loan_status)) +
  geom_bar(position = "fill") +
  labs(title="relationship of loan status to grade", x="grade",y="pct default")


loan %>%
  group_by(term, loan_status) %>%
  summarise(n=n())

loan %>%
  ggplot(aes(term, fill=loan_status)) +
  geom_bar(position = "fill") +
  labs(title="relationship of loan status to term", x="term",y="pct default")


loan %>%
  ggplot(aes(fico_range_low, fill=loan_status)) +
  geom_histogram(bins=50, position = "fill") +
  labs(title="relationship of loan status to fico_range_low", x="fico_range_low",y="pct default")

loan %>%
  group_by(purpose, loan_status) %>%
  summarise(n=n())

loan %>%
  ggplot(aes(purpose, fill=loan_status)) +
  geom_bar(position = "fill") +
  labs(title="relationship of loan status to purpose", x="purpose",y="pct default") +
  scale_x_discrete(guide = guide_axis(n.dodge=3))
```

```{r}
loan %>% 
  skim() 

loan <- loan %>%
  mutate(loan_status = as.factor(loan_status)) %>%
  mutate_if(is.character,factor)

model_recipe <- recipe(loan_status ~  ., data=train  ) %>%
  step_rm(emp_title, url, desc, title, next_pymnt_d, id, member_id, mths_since_last_delinq, mths_since_last_record) %>% 
  step_impute_median(all_numeric_predictors())  %>%
  step_impute_mode(all_nominal_predictors()) %>%
  step_zv(all_numeric_predictors()) %>%
  step_center(all_numeric_predictors())  %>%
  step_unknown(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
  step_nzv(all_predictors()) %>%
  prep()
```

```{r}
# logistic
bake_train <- bake(model_recipe, new_data = train)
bake_test  <- bake(model_recipe, new_data = test)

logistic_glm <-logistic_reg(mode = "classification") %>%
                  set_engine("glm") %>%
                  fit(loan_status ~ ., data = bake_train)

tidy(logistic_glm) %>%
  mutate_at(c("estimate", "std.error", "statistic", "p.value"),round, 4)
```


```{r}

# Training
predict(logistic_glm, bake_train, type = "prob") %>%
  bind_cols(.,predict(logistic_glm, bake_train)) %>%
  bind_cols(.,bake_train) -> scored_train_glm

head(scored_train_glm)

# Test
predict(logistic_glm, bake_test, type = "prob") %>%
  bind_cols(.,predict(logistic_glm, bake_test)) %>%
  bind_cols(.,bake_test) -> scored_test_glm

head(scored_test_glm)

# -- AUC: Train and Test 
scored_train_glm %>% 
  metrics(loan_status, .pred_default, estimate = .pred_class) %>%
  mutate(part="training") %>%
  bind_rows( scored_test_glm %>% 
               metrics(loan_status, .pred_default, estimate = .pred_class) %>%
               mutate(part="testing") 
  ) %>%
  filter(.metric %in% c('accuracy', 'roc_auc', 'mn_log_loss'))


# -- Variable Importance top 10 features  
logistic_glm %>%
  vip(num_features = 10) + 
  labs(title="Logistic Variable Importance")

# -- ROC Charts 
scored_train_glm %>%
  mutate(model = "train") %>%
  bind_rows(scored_test_glm %>%
              mutate(model="test")) %>%
  group_by(model) %>%
  roc_curve(loan_status, .pred_default) %>%
  autoplot() %>% + 
  labs(title="Logistic ROC Curve")


# precision @0.5
scored_train_glm %>% 
  mutate(part="training") %>%
  bind_rows( scored_test_glm %>%
               mutate(part="testing") 
  )%>%
  group_by(part) %>%
  precision(loan_status, .pred_class)

# recall @0.5
scored_train_glm %>% 
  mutate(part="training") %>%
  bind_rows( scored_test_glm %>%
               mutate(part="testing") 
  )%>%
  group_by(part) %>%
  recall(loan_status, .pred_class)

# precision and recall
scored_test_glm %>% 
  pr_curve(loan_status, .pred_default) %>%
  ggplot(aes(x = recall, y = precision)) +
  geom_path() +
  coord_equal() + 
  labs(title="Logistic Precision Recall Curve")

# operating range table 
xgb_operating_range <- scored_test_glm %>%
  roc_curve(loan_status, .pred_default)  %>%
  mutate(
    fpr = round((1 - specificity), 2),
    tpr = round(sensitivity, 3),
    score_threshold =  round(.threshold, 3)
  ) %>%
  group_by(fpr) %>%
  summarise(threshold = round(mean(score_threshold),3),
            tpr = mean(tpr)) %>%
  filter(fpr <= 0.1)
xgb_operating_range

# score distribution for test dataset 
scored_test_glm %>%
  ggplot(aes(.pred_default, fill = loan_status)) +
  geom_histogram(bins = 50) +
  geom_vline(xintercept = 0.5, color = "red") +
  labs(
    title = paste("Distribution of the Probabilty of default:", "Logistic Model") ,
    x = ".pred_default",
    y = "count"
  ) 

# -- Confustion Matricies  
scored_train_glm %>%
  conf_mat(loan_status, .pred_class) %>%
  autoplot( type = "heatmap") +
  labs(title="Logistic Train Confusion Matrix")

scored_test_glm %>%
  conf_mat(loan_status, .pred_class) %>%
  autoplot( type = "heatmap") +
  labs(title="Logistic Test Confusion Matrix")
```
```{r}
# Logistic Global Importance

logistic_glm %>%
    vip(10) + 
    labs("Logistic VIP") 

logistic_explainer <- explain_tidymodels(
  logistic_glm,
  data = train ,
  y = train$loan_default ,
  verbose = TRUE
)

# credit
logistic_credit <- model_profile(
  logistic_explainer,
  variables = c("last_credit_pull_d")
)

```

```{r}
# XGB model

xgb_model <- boost_tree(trees=tune(), 
                        learn_rate = tune(),
                        tree_depth = tune()) %>%
  set_engine("xgboost", 
             importance="permutation") %>%
  set_mode("classification")


xgb_wflow <-workflow() %>%
  add_recipe(model_recipe) %>%
  add_model(xgb_model)


xgb_search <- xgb_wflow %>% 
  tune_bayes(
    resamples = kfold_splits,
    # Generate five at semi-random to start
    initial = 5,
    iter = 60, 
    # How to measure performance?
    metrics = metric_set(roc_auc,accuracy),
    control = control_bayes(no_improve = 5, verbose = TRUE)
  )

lowest_xgb_auc <- xgb_search %>%
  select_best("roc_auc")

xgb_wflow <- finalize_workflow(
  xgb_wflow, lowest_xgb_auc
) %>% 
  fit(train)


##### Tuned

xgb_model <- boost_tree(trees=1276, 
                        learn_rate = 0.05953159,
                        tree_depth = 7) %>%
  set_engine("xgboost",importance="permutation") %>%
  set_mode("classification")


xgb_final <-workflow() %>%
  add_recipe(model_recipe) %>%
  add_model(xgb_model) %>%
  fit(train)

```


```{r}
# XGB model evaluation
bind_cols(
  predict(xgb_final,train, type="prob"), 
  predict(xgb_final,train, type="class"),
  train) %>% 
  mutate(part = "train") -> score_xgb_train

bind_cols(
  predict(xgb_final,test, type="prob"), 
   predict(xgb_final,test, type="class"),
  test) %>% 
  mutate(part = "test") -> score_xgb_test

options(yardstick.event_first = FALSE)
score_xgb_train %>% 
  metrics(loan_status, .pred_default, estimate = .pred_class) %>%
  mutate(part="training") %>%
  bind_rows(score_xgb_test %>% 
               metrics(loan_status, .pred_default, estimate = .pred_class) %>%
               mutate(part="testing") 
  ) %>%
  filter(.metric %in% c('accuracy', 'roc_auc', 'mn_log_loss'))

options(yardstick.event_first = FALSE)
# ROC Curve 
bind_rows(score_xgb_train, score_xgb_test) %>%
  group_by(part) %>%
  roc_curve(truth=loan_status, predicted=.pred_default) %>% 
  autoplot() +
  labs(title = "XGB ROC Curve") -> roc_chart 

print(roc_chart)

# precision @0.5
bind_rows(score_xgb_train, score_xgb_test) %>%
  group_by(part) %>%
  precision(loan_status, .pred_class)
# recall @0.5
bind_rows(score_xgb_train, score_xgb_test) %>%
  group_by(part) %>%
  recall(loan_status, .pred_class)

# precision and recall
score_xgb_test %>% 
  pr_curve(loan_status, .pred_default) %>%
  ggplot(aes(x = recall, y = precision)) +
  geom_path() +
  coord_equal() + 
  labs(title="XGB Precision Recall Curve")

# operating range table 
xgb_operating_range <- score_xgb_test %>%
  roc_curve(loan_status, .pred_default)  %>%
  mutate(
    fpr = round((1 - specificity), 2),
    tpr = round(sensitivity, 3),
    score_threshold =  round(.threshold, 3)
  ) %>%
  group_by(fpr) %>%
  summarise(threshold = round(mean(score_threshold),3),
            tpr = mean(tpr)) %>%
  filter(fpr <= 0.1)
xgb_operating_range

# score distribution for test dataset 
score_xgb_test %>%
  ggplot(aes(.pred_default, fill = loan_status)) +
  geom_histogram(bins = 50) +
  geom_vline(xintercept = 0.5, color = "red") +
  labs(
    title = paste("Distribution of the Probabilty of default:", "XGB Model") ,
    x = ".pred_default",
    y = "count"
  ) 

# -- Confustion Matricies  
score_xgb_train %>%
  conf_mat(loan_status, .pred_class) %>%
  autoplot( type = "heatmap") +
  labs(title="XGB Train Confusion Matrix")

score_xgb_test %>%
  conf_mat(loan_status, .pred_class) %>%
  autoplot( type = "heatmap") +
  labs(title="XGB Test Confusion Matrix")

#
xgb_final %>%
    pull_workflow_fit() %>%
    vip(10) + 
    labs(title = "XGB Variable Importance") 

```
```{r}
# XGB Global Importance

xgb_final %>%
    pull_workflow_fit() %>%
    vip(10) + 
    labs("XGB VIP") 

xgb_explainer <- explain_tidymodels(
  xgb_final,
  data = train ,
  y = train$loan_default ,
  verbose = TRUE
)

# credit
xgb_credit <- model_profile(
  xgb_explainer,
  variables = c("last_credit_pull_d")
)


as_tibble(xgb_credit$agr_profiles) %>%
  mutate(profile_variable = `_x_`,
         avg_prediction_impact = `_yhat_`) %>%
  ggplot(aes(x=profile_variable, y=avg_prediction_impact)) +
  geom_col() +
  labs(
    x = "Variable: Loan last_credit_pull_d",
     y = " Average prediction Impact ",
    color = NULL,
    title = "Partial dependence plot Loan last_credit_pull_d",
    subtitle = "How does last_credit_pull_d impact predictions (on average)"
  ) +
  scale_x_discrete(guide = guide_axis(n.dodge=10))


# pyment
xgb_pymnt <- model_profile(
  xgb_explainer,
  variables = c("last_pymnt_amnt")
)

as_tibble(xgb_pymnt$agr_profiles) %>%
  mutate(profile_variable = `_x_`,
         avg_prediction_impact = `_yhat_`) %>%
  ggplot(aes(x=profile_variable, y=avg_prediction_impact)) +
  geom_line() +
  labs(
    x = "Variable: Loan last_pymnt_amnt",
     y = " Average prediction Impact ",
    color = NULL,
    title = "Partial dependence plot Loan last_pymnt_amnt",
    subtitle = "How does last_pymnt_amnt impact predictions (on average)"
  ) + coord_cartesian(xlim=c(0,10000))

# installment
xgb_installment <- model_profile(
  xgb_explainer,
  variables = c("installment")
)


as_tibble(xgb_installment$agr_profiles) %>%
  mutate(profile_variable = `_x_`,
         avg_prediction_impact = `_yhat_`) %>%
  ggplot(aes(x=profile_variable, y=avg_prediction_impact)) +
  geom_line() +
  labs(
    x = "Variable: Loan installment",
     y = " Average prediction Impact ",
    color = NULL,
    title = "Partial dependence plot Loan installment",
    subtitle = "How does installment impact predictions (on average)"
  )

# revol_bal
xgb_revol_bal <- model_profile(
  xgb_explainer,
  variables = c("revol_bal")
)


as_tibble(xgb_revol_bal$agr_profiles) %>%
  mutate(profile_variable = `_x_`,
         avg_prediction_impact = `_yhat_`) %>%
  ggplot(aes(x=profile_variable, y=avg_prediction_impact)) +
  geom_line() +
  labs(
    x = "Variable: Loan revol_bal",
     y = " Average prediction Impact ",
    color = NULL,
    title = "Partial dependence plot Loan revol_bal",
    subtitle = "How does revol_bal impact predictions (on average)"
  )

# annual_inc
xgb_annual_inc <- model_profile(
  xgb_explainer,
  variables = c("annual_inc")
)


as_tibble(xgb_annual_inc$agr_profiles) %>%
  mutate(profile_variable = `_x_`,
         avg_prediction_impact = `_yhat_`) %>%
  ggplot(aes(x=profile_variable, y=avg_prediction_impact)) +
  geom_line() +
  labs(
    x = "Variable: Loan annual_inc",
     y = " Average prediction Impact ",
    color = NULL,
    title = "Partial dependence plot Loan annual_inc",
    subtitle = "How does annual_inc impact predictions (on average)"
  )

```
```{r}
# Local Importance

xgb_explainer <- 
  explain_tidymodels(
    xgb_final,   # fitted workflow object 
    data = train,    # original training data
    y = train$default, # predicted outcome 
    label = "xgboost",
    verbose = FALSE
  )

# high scoring(pred=TRUE) did default(actual=TRUE)
top_10_tp <- score_xgb_test %>%
  filter(.pred_class == "default") %>%
  filter(loan_status == "default") %>%
  slice_max(.pred_default,n=10) 

# high scoring(pred=TRUE) but actually didnâ€™t default(actual=FALSE)
top_10_fp <- score_xgb_test %>%
  filter(.pred_class == "default") %>%
   filter(loan_status == "current" ) %>%
  slice_max(.pred_default,n=10)

# low scoring(pred=FALSE) but did default(actual=TRUE)
top_10_fn <- score_xgb_test %>%
  filter(.pred_class != loan_status ) %>%
  filter(loan_status == "default" ) %>%
  slice_min(.pred_default,n=10)

record_shap <- predict_parts(explainer = xgb_explainer, 
                               new_observation = top_10_tp,
                               type="break_down")
record_shap %>% plot() %>% print()

record_shap <- predict_parts(explainer = xgb_explainer, 
                               new_observation = top_10_fp,
                               type="break_down")
record_shap %>% plot() %>% print()

record_shap <- predict_parts(explainer = xgb_explainer, 
                               new_observation = top_10_fn,
                               type="break_down")
record_shap %>% plot() %>% print()

```


```{r}

# neural network model

train_scaled <- train %>%
  mutate_if(is.numeric, funs(./255)) 

test_scaled <- test %>%
  mutate_if(is.numeric, funs(./255)) 

mnist_recipe <- recipe(loan_status ~ ., train_scaled) 


nn_model <- mlp(hidden_units = tune(),
                 penalty=tune(),
  epochs = tune(),
  ) %>%
  set_engine("nnet") %>%
  set_mode("classification") 

nn_wflow <-workflow() %>%
  add_recipe(model_recipe) %>%
  add_model(nn_model) 

nn_search_res <- nn_wflow %>% 
  tune_bayes(
    resamples = kfold_splits,
    # Generate five at semi-random to start
    initial = 5,
    iter = 60, 
    # How to measure performance?
    metrics = metric_set(roc_auc),
    control = control_bayes(no_improve = 5, verbose = TRUE)
  )

nn_search_res %>%
  collect_metrics()  

nn_search_res %>%
  select_best("roc_auc")

best_auc <- nn_search_res %>%
  select_best("roc_auc")

best_auc

nn_final <- finalize_workflow(
  nn_wflow, best_auc
) %>% 
  fit(train)

#### tuned
nn_model <- mlp(hidden_units = 2,
                 penalty= 0.9866663,
  epochs = 993,
  ) %>%
  set_engine("nnet") %>%
  set_mode("classification") 

nn_final <-workflow() %>%
  add_recipe(model_recipe) %>%
  add_model(nn_model) %>%
  fit(train)
```


```{r}
# neural network evaluation 

bind_cols(
  predict(nn_final,train, type="prob"), 
  predict(nn_final,train, type="class"),
  train) %>% 
  mutate(part = "train") -> score_nn_train

bind_cols(
  predict(nn_final,test, type="prob"), 
   predict(nn_final,test, type="class"),
  test) %>% 
  mutate(part = "test") -> score_nn_test

score_nn_train %>% 
  metrics(loan_status, .pred_default, estimate = .pred_class) %>%
  mutate(part="training") %>%
  bind_rows(score_nn_test %>% 
               metrics(loan_status, .pred_default, estimate = .pred_class) %>%
               mutate(part="testing") 
  ) %>%
  filter(.metric %in% c('accuracy', 'roc_auc', 'mn_log_loss'))

options(yardstick.event_first = FALSE)
# ROC Curve 
bind_rows(score_nn_train, score_nn_test) %>%
  group_by(part) %>%
  roc_curve(truth=loan_status, predicted=.pred_default) %>% 
  autoplot() +
   labs(title = "Neural Network network model") -> roc_chart 

print(roc_chart)

# precision @0.5
bind_rows(score_nn_train, score_nn_test) %>%
  group_by(part) %>%
  precision(loan_status, .pred_class)
# recall @0.5
bind_rows(score_nn_train, score_nn_test) %>%
  group_by(part) %>%
  recall(loan_status, .pred_class)

# precision and recall
score_nn_test %>% 
  pr_curve(loan_status, .pred_default) %>%
  ggplot(aes(x = recall, y = precision)) +
  geom_path() +
  coord_equal() + 
  labs(title="Neural Network Precision Recall Curve")

# operating range table 
xgb_operating_range <- score_nn_test %>%
  roc_curve(loan_status, .pred_default)  %>%
  mutate(
    fpr = round((1 - specificity), 2),
    tpr = round(sensitivity, 3),
    score_threshold =  round(.threshold, 3)
  ) %>%
  group_by(fpr) %>%
  summarise(threshold = round(mean(score_threshold),3),
            tpr = mean(tpr)) %>%
  filter(fpr <= 0.1)
xgb_operating_range

# score distribution for test dataset 
score_nn_test %>%
  ggplot(aes(.pred_default, fill = loan_status)) +
  geom_histogram(bins = 50) +
  geom_vline(xintercept = 0.5, color = "red") +
  labs(
    title = paste("Distribution of the Probabilty of default:", "Neural Network Model") ,
    x = ".pred_default",
    y = "count"
  ) 

# -- Confustion Matricies  
score_nn_train %>%
  conf_mat(loan_status, .pred_class) %>%
  autoplot( type = "heatmap") +
  labs(title="Neural Network Train Confusion Matrix")

score_nn_test %>%
  conf_mat(loan_status, .pred_class) %>%
  autoplot( type = "heatmap") +
  labs(title="Neural Network Test Confusion Matrix")

nn_final %>%
    pull_workflow_fit() %>%
    vip(10) + 
    labs(title = "Neural Network Variable Importance") 
```

```{r}
# Neural Network Global Importance

nn_final %>%
    pull_workflow_fit() %>%
    vip(10) + 
    labs("nn VIP") 

nn_explainer <- explain_tidymodels(
  nn_final,
  data = train ,
  y = train$loan_default ,
  verbose = TRUE
)

# credit
nn_credit <- model_profile(
  nn_explainer,
  variables = c("last_credit_pull_d")
)

as_tibble(nn_credit$agr_profiles) %>%
  mutate(profile_variable = `_x_`,
         avg_prediction_impact = `_yhat_`) %>%
  ggplot(aes(x=profile_variable, y=avg_prediction_impact)) +
  geom_col() +
  labs(
    x = "Variable: Loan last_credit_pull_d",
     y = " Average prediction Impact ",
    color = NULL,
    title = "Partial dependence plot Loan last_credit_pull_d",
    subtitle = "How does last_credit_pull_d impact predictions (on average)"
  ) +
  scale_x_discrete(guide = guide_axis(n.dodge=10))

# addr_state
nn_addr_state <- model_profile(
  nn_explainer,
  variables = c("addr_state")
)

as_tibble(nn_addr_state$agr_profiles) %>%
  mutate(profile_variable = `_x_`,
         avg_prediction_impact = `_yhat_`) %>%
  ggplot(aes(x=profile_variable, y=avg_prediction_impact)) +
  geom_col() +
  labs(
    x = "Variable: Loan addr_state",
     y = " Average prediction Impact ",
    color = NULL,
    title = "Partial dependence plot Loan addr_state",
    subtitle = "How does addr_state impact predictions (on average)"
  ) +
  scale_x_discrete(guide = guide_axis(n.dodge=3))

# pub_rec
nn_pub_rec <- model_profile(
  nn_explainer,
  variables = c("pub_rec")
)

as_tibble(nn_pub_rec$agr_profiles) %>%
  mutate(profile_variable = `_x_`,
         avg_prediction_impact = `_yhat_`) %>%
  ggplot(aes(x=profile_variable, y=avg_prediction_impact)) +
  geom_line() +
  labs(
    x = "Variable: Loan pub_rec",
     y = " Average prediction Impact ",
    color = NULL,
    title = "Partial dependence plot Loan pub_rec",
    subtitle = "How does pub_rec impact predictions (on average)"
  ) 

# sub_grade
nn_sub_grade <- model_profile(
  nn_explainer,
  variables = c("sub_grade")
)

as_tibble(nn_sub_grade$agr_profiles) %>%
  mutate(profile_variable = `_x_`,
         avg_prediction_impact = `_yhat_`) %>%
  ggplot(aes(x=profile_variable, y=avg_prediction_impact)) +
  geom_col() +
  labs(
    x = "Variable: Loan sub_grade",
     y = " Average prediction Impact ",
    color = NULL,
    title = "Partial dependence plot Loan sub_grade",
    subtitle = "How does sub_grade impact predictions (on average)"
  ) 

# inq_last_6mths
nn_inq_last_6mths <- model_profile(
  nn_explainer,
  variables = c("inq_last_6mths")
)

as_tibble(nn_inq_last_6mths$agr_profiles) %>%
  mutate(profile_variable = `_x_`,
         avg_prediction_impact = `_yhat_`) %>%
  ggplot(aes(x=profile_variable, y=avg_prediction_impact)) +
  geom_line() +
  labs(
    x = "Variable: Loan inq_last_6mths",
     y = " Average prediction Impact ",
    color = NULL,
    title = "Partial dependence plot Loan inq_last_6mths",
    subtitle = "How does inq_last_6mths impact predictions (on average)"
  ) 
```

```{r}
loan_kaggle <- read_csv("loan_holdout.csv") 
loan_kaggle %>% skim()

scored_kaggle <- predict(xgb_final, loan_kaggle, type="prob") %>%
       bind_cols(., loan_kaggle) %>%
      dplyr::select(id, .pred_default)

scored_kaggle %>%
  write_csv("submission_loan.csv")
```

